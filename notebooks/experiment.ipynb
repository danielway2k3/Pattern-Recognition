{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":365400,"sourceType":"datasetVersion","datasetId":159484}],"dockerImageVersionId":30788,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Imports","metadata":{}},{"cell_type":"code","source":"from mpl_toolkits.mplot3d import Axes3D\nfrom sklearn.preprocessing import StandardScaler\nfrom scipy.io import loadmat\nimport matplotlib.pyplot as plt \nimport numpy as np \nimport os \nimport pandas as pd\nfrom scipy.stats import mode  # For consensus calculation\n\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import MaxPooling2D, GlobalAveragePooling2D\nfrom tensorflow.keras.layers import Bidirectional\n\nfrom tensorflow.keras.layers import Conv2D, AveragePooling2D, Dropout, TimeDistributed, Flatten, LSTM, Dense\nfrom tensorflow.keras.utils import to_categorical\nfrom tensorflow.keras.callbacks import EarlyStopping\nfrom sklearn.model_selection import train_test_split\nfrom tensorflow.keras.metrics import Precision, Recall, AUC\nimport tensorflow.keras.backend as K\n\nfrom tensorflow.keras.layers import BatchNormalization\nfrom sklearn.metrics import confusion_matrix, classification_report\nimport seaborn as sns\nfrom scipy.signal import butter, lfilter\nimport numpy as np\n\n\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-04-13T16:39:17.634440Z","iopub.execute_input":"2025-04-13T16:39:17.635236Z","iopub.status.idle":"2025-04-13T16:39:17.640977Z","shell.execute_reply.started":"2025-04-13T16:39:17.635203Z","shell.execute_reply":"2025-04-13T16:39:17.640095Z"}},"outputs":[],"execution_count":17},{"cell_type":"markdown","source":"# Data labeling","metadata":{}},{"cell_type":"code","source":"columns = [\n    'ED_COUNTER',    'ED_INTERPOLATED',    'ED_RAW_CQ',    'ED_AF3',    'ED_F7',\n    'ED_F3',    'ED_FC5',    'ED_T7',    'ED_P7',    'ED_O1',\n    'ED_O2',    'ED_P8',    'ED_T8',    'ED_FC6',    'ED_F4',\n    'ED_F8',    'ED_AF4',    'ED_GYROX',    'ED_GYROY',    'ED_TIMESTAMP',\n    'ED_ES_TIMESTAMP',    'ED_FUNC_ID',    'ED_FUNC_VALUE',    'ED_MARKER',    'ED_SYNC_SIGNAL'\n]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-13T16:39:20.244305Z","iopub.execute_input":"2025-04-13T16:39:20.244871Z","iopub.status.idle":"2025-04-13T16:39:20.249128Z","shell.execute_reply.started":"2025-04-13T16:39:20.244836Z","shell.execute_reply":"2025-04-13T16:39:20.248194Z"}},"outputs":[],"execution_count":18},{"cell_type":"code","source":"FOCUSED_ID = 0\nUNFOCUSED_ID = 1\nDROWSY_ID = 2\n\ndef get_state(timestamp):\n    if timestamp <= 10*128*60:\n        return FOCUSED_ID\n    elif timestamp > 20*128*60:\n        return UNFOCUSED_ID\n    else:\n        return DROWSY_ID","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-13T16:39:21.294282Z","iopub.execute_input":"2025-04-13T16:39:21.294943Z","iopub.status.idle":"2025-04-13T16:39:21.299112Z","shell.execute_reply.started":"2025-04-13T16:39:21.294909Z","shell.execute_reply":"2025-04-13T16:39:21.298251Z"}},"outputs":[],"execution_count":19},{"cell_type":"markdown","source":"# Data preprocessing","metadata":{}},{"cell_type":"code","source":"# Bandpass filter function\ndef bandpass_filter(data, low_freq, high_freq, fs, order=4):\n    nyquist = 0.5 * fs\n    low = low_freq / nyquist\n    high = high_freq / nyquist\n    b, a = butter(order, [low, high], btype='band')\n    return lfilter(b, a, data)\n\n# Brainwave frequency ranges\nbrainwave_ranges = {\n    \"Delta\": (0.5, 4),\n    \"Theta\": (4, 8),\n    \"Alpha\": (8, 13),\n    \"Beta\": (13, 30)\n}\n\n# Parameters\nfeatures = []\ndelta_features = []\ntheta_features = []\nalpha_features = []\nbeta_features = []\nlabels = []\nSAMPLE_LENGTH_SECOND = 4\nFREQUENCY_HZ = 128\nSAMPLE_LENGTH_HZ = FREQUENCY_HZ * SAMPLE_LENGTH_SECOND\nscaler = StandardScaler(with_mean=True, with_std=True)\n\n# File extraction loop\nfor i in range(1, 35):\n    print(f\"Extracting file {i}\")\n    mat_data = loadmat(f'/kaggle/input/eeg-data-for-mental-attention-state-detection/EEG Data/eeg_record{i}.mat')\n    data = mat_data['o'][0][0]['data']\n    eeg_df = pd.DataFrame(data, columns=columns)\n    eeg_df.reset_index(inplace=True)\n    eeg_df.rename(columns={'index': 'timestamp'}, inplace=True)\n    eeg_df['state'] = eeg_df['timestamp'].apply(get_state)\n\n    # Extract original EEG features\n    feature = eeg_df.iloc[:, 4:18].values  # Columns 4 to 17 (0-indexed)\n    label = eeg_df['state'].values\n\n    # Scale the original EEG features\n    feature = scaler.fit_transform(feature)\n\n    # Apply bandpass filters for each brainwave type\n    brainwave_features = {}\n    for wave, (low, high) in brainwave_ranges.items():\n        filtered = np.apply_along_axis(\n            bandpass_filter, 0, feature, low, high, FREQUENCY_HZ\n        )\n        brainwave_features[wave] = filtered  # Do not scale these\n\n    # Reshape for sample segments\n    num_samples = len(feature) // SAMPLE_LENGTH_HZ\n    feature = feature[:num_samples * SAMPLE_LENGTH_HZ]\n    label = label[:num_samples * SAMPLE_LENGTH_HZ]\n\n    # Original feature\n    feature = feature.reshape(num_samples, SAMPLE_LENGTH_HZ, 14, 1)\n    label = label.reshape(num_samples, SAMPLE_LENGTH_HZ)\n    consensus_labels = mode(label, axis=1)[0].flatten()\n\n    # Append original and brainwave-specific features\n    features.append(feature)\n    labels.append(consensus_labels)\n\n    for wave in brainwave_ranges.keys():\n        brainwave_feature = brainwave_features[wave][:num_samples * SAMPLE_LENGTH_HZ]\n        brainwave_feature = brainwave_feature.reshape(num_samples, SAMPLE_LENGTH_HZ, 14, 1)\n        if wave == \"Delta\":\n            delta_features.append(brainwave_feature)\n        elif wave == \"Theta\":\n            theta_features.append(brainwave_feature)\n        elif wave == \"Alpha\":\n            alpha_features.append(brainwave_feature)\n        elif wave == \"Beta\":\n            beta_features.append(brainwave_feature)\n\n# Combine all features and labels\nfeatures = np.vstack(features)\ndelta_features = np.vstack(delta_features)\ntheta_features = np.vstack(theta_features)\nalpha_features = np.vstack(alpha_features)\nbeta_features = np.vstack(beta_features)\nlabels = np.concatenate(labels)\n\n# Print final shapes\nprint(f\"Delta Features Shape: {delta_features.shape}\")\nprint(f\"Theta Features Shape: {theta_features.shape}\")\nprint(f\"Alpha Features Shape: {alpha_features.shape}\")\nprint(f\"Beta Features Shape: {beta_features.shape}\")\nprint(f\"Final Labels Shape: {labels.shape}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-13T16:39:26.975336Z","iopub.execute_input":"2025-04-13T16:39:26.976370Z","iopub.status.idle":"2025-04-13T16:39:58.924232Z","shell.execute_reply.started":"2025-04-13T16:39:26.976332Z","shell.execute_reply":"2025-04-13T16:39:58.923327Z"}},"outputs":[{"name":"stdout","text":"Extracting file 1\nExtracting file 2\nExtracting file 3\nExtracting file 4\nExtracting file 5\nExtracting file 6\nExtracting file 7\nExtracting file 8\nExtracting file 9\nExtracting file 10\nExtracting file 11\nExtracting file 12\nExtracting file 13\nExtracting file 14\nExtracting file 15\nExtracting file 16\nExtracting file 17\nExtracting file 18\nExtracting file 19\nExtracting file 20\nExtracting file 21\nExtracting file 22\nExtracting file 23\nExtracting file 24\nExtracting file 25\nExtracting file 26\nExtracting file 27\nExtracting file 28\nExtracting file 29\nExtracting file 30\nExtracting file 31\nExtracting file 32\nExtracting file 33\nExtracting file 34\nDelta Features Shape: (24418, 512, 14, 1)\nTheta Features Shape: (24418, 512, 14, 1)\nAlpha Features Shape: (24418, 512, 14, 1)\nBeta Features Shape: (24418, 512, 14, 1)\nFinal Labels Shape: (24418,)\n","output_type":"stream"}],"execution_count":20},{"cell_type":"markdown","source":"# Data classes distribution","metadata":{}},{"cell_type":"code","source":"import numpy as np\n\n# Use numpy's unique and counts to count class samples\nunique_classes, class_counts = np.unique(labels, return_counts=True)\n\n# Display the counts\nfor cls, count in zip(unique_classes, class_counts):\n    print(f\"Class {cls}: {count} samples\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-13T16:39:58.925569Z","iopub.execute_input":"2025-04-13T16:39:58.925854Z","iopub.status.idle":"2025-04-13T16:39:58.931513Z","shell.execute_reply.started":"2025-04-13T16:39:58.925827Z","shell.execute_reply":"2025-04-13T16:39:58.930601Z"}},"outputs":[{"name":"stdout","text":"Class 0: 5100 samples\nClass 1: 14218 samples\nClass 2: 5100 samples\n","output_type":"stream"}],"execution_count":21},{"cell_type":"code","source":"# Prepare the data\nX = features  # Already shaped as (samples, 728, 14, 1)\ny = labels    # Class labels (numeric)\n\ndel features\ndel labels\n# One-hot encode the labels (3 classes)\ny = to_categorical(y, num_classes=3)\n\n# Split the data into training and testing sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-13T16:39:58.932603Z","iopub.execute_input":"2025-04-13T16:39:58.932969Z","iopub.status.idle":"2025-04-13T16:39:59.344231Z","shell.execute_reply.started":"2025-04-13T16:39:58.932940Z","shell.execute_reply":"2025-04-13T16:39:59.343299Z"}},"outputs":[],"execution_count":22},{"cell_type":"code","source":"eeg_df","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-13T16:39:59.346484Z","iopub.execute_input":"2025-04-13T16:39:59.347129Z","iopub.status.idle":"2025-04-13T16:39:59.419098Z","shell.execute_reply.started":"2025-04-13T16:39:59.347084Z","shell.execute_reply":"2025-04-13T16:39:59.418311Z"}},"outputs":[{"execution_count":23,"output_type":"execute_result","data":{"text/plain":"        timestamp  ED_COUNTER  ED_INTERPOLATED  ED_RAW_CQ       ED_AF3  \\\n0               0       120.0              0.0        0.0  4445.641026   \n1               1       121.0              0.0        0.0  4447.179487   \n2               2       122.0              0.0        0.0  4446.666667   \n3               3       123.0              0.0      429.0  4446.666667   \n4               4       124.0              0.0        0.0  4448.717949   \n...           ...         ...              ...        ...          ...   \n408971     408971        48.0              0.0        0.0  4449.230769   \n408972     408972        49.0              0.0        0.0  4448.205128   \n408973     408973        50.0              0.0        0.0  4445.641026   \n408974     408974        51.0              0.0        0.0  4446.666667   \n408975     408975        52.0              0.0        0.0  4445.641026   \n\n              ED_F7        ED_F3       ED_FC5        ED_T7        ED_P7  ...  \\\n0       3955.384615  5040.000000  3830.769231  4047.179487  4200.512821  ...   \n1       3960.512821  5047.692308  3831.282051  4050.256410  4208.205128  ...   \n2       3960.000000  5046.153846  3831.282051  4045.641026  4201.538462  ...   \n3       3954.358974  5036.923077  3830.769231  4044.102564  4189.743590  ...   \n4       3952.820513  5034.358974  3833.333333  4046.153846  4187.692308  ...   \n...             ...          ...          ...          ...          ...  ...   \n408971  3960.000000  5003.076923  3832.820513  4048.205128  4270.769231  ...   \n408972  3959.487179  5008.717949  3833.846154  4045.641026  4276.410256  ...   \n408973  3960.000000  5014.871795  3831.794872  4046.666667  4273.333333  ...   \n408974  3959.487179  5024.102564  3828.717949  4045.128205  4274.871795  ...   \n408975  3960.512821  5029.743590  3828.205128  4038.461538  4281.025641  ...   \n\n             ED_AF4  ED_GYROX  ED_GYROY  ED_TIMESTAMP  ED_ES_TIMESTAMP  \\\n0       4076.410256    1569.0    1715.0       242.409         0.031277   \n1       4086.666667    1570.0    1715.0       242.417         0.031277   \n2       4089.230769    1572.0    1714.0       242.426         0.031277   \n3       4076.923077    1574.0    1714.0       242.433         0.031277   \n4       4068.205128    1577.0    1713.0       242.440         0.031277   \n...             ...       ...       ...           ...              ...   \n408971  4272.820513    1574.0    1739.0      3440.381      3197.802734   \n408972  4278.974359    1574.0    1740.0      3440.389      3197.802734   \n408973  4275.897436    1575.0    1740.0      3440.397      3197.802734   \n408974  4272.820513    1575.0    1740.0      3440.405      3197.802734   \n408975  4278.461538    1577.0    1738.0      3440.412      3197.802734   \n\n        ED_FUNC_ID  ED_FUNC_VALUE  ED_MARKER  ED_SYNC_SIGNAL  state  \n0              0.0            0.0        0.0             0.0      0  \n1              0.0            0.0        0.0             0.0      0  \n2              0.0            0.0        0.0             0.0      0  \n3              0.0            0.0        0.0             0.0      0  \n4              0.0            0.0        0.0             0.0      0  \n...            ...            ...        ...             ...    ...  \n408971         0.0            0.0        0.0             0.0      1  \n408972         0.0            0.0        0.0             0.0      1  \n408973         0.0            0.0        0.0             0.0      1  \n408974         0.0            0.0        0.0             0.0      1  \n408975         0.0            0.0        0.0             0.0      1  \n\n[408976 rows x 27 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>timestamp</th>\n      <th>ED_COUNTER</th>\n      <th>ED_INTERPOLATED</th>\n      <th>ED_RAW_CQ</th>\n      <th>ED_AF3</th>\n      <th>ED_F7</th>\n      <th>ED_F3</th>\n      <th>ED_FC5</th>\n      <th>ED_T7</th>\n      <th>ED_P7</th>\n      <th>...</th>\n      <th>ED_AF4</th>\n      <th>ED_GYROX</th>\n      <th>ED_GYROY</th>\n      <th>ED_TIMESTAMP</th>\n      <th>ED_ES_TIMESTAMP</th>\n      <th>ED_FUNC_ID</th>\n      <th>ED_FUNC_VALUE</th>\n      <th>ED_MARKER</th>\n      <th>ED_SYNC_SIGNAL</th>\n      <th>state</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>120.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>4445.641026</td>\n      <td>3955.384615</td>\n      <td>5040.000000</td>\n      <td>3830.769231</td>\n      <td>4047.179487</td>\n      <td>4200.512821</td>\n      <td>...</td>\n      <td>4076.410256</td>\n      <td>1569.0</td>\n      <td>1715.0</td>\n      <td>242.409</td>\n      <td>0.031277</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>121.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>4447.179487</td>\n      <td>3960.512821</td>\n      <td>5047.692308</td>\n      <td>3831.282051</td>\n      <td>4050.256410</td>\n      <td>4208.205128</td>\n      <td>...</td>\n      <td>4086.666667</td>\n      <td>1570.0</td>\n      <td>1715.0</td>\n      <td>242.417</td>\n      <td>0.031277</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>122.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>4446.666667</td>\n      <td>3960.000000</td>\n      <td>5046.153846</td>\n      <td>3831.282051</td>\n      <td>4045.641026</td>\n      <td>4201.538462</td>\n      <td>...</td>\n      <td>4089.230769</td>\n      <td>1572.0</td>\n      <td>1714.0</td>\n      <td>242.426</td>\n      <td>0.031277</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>123.0</td>\n      <td>0.0</td>\n      <td>429.0</td>\n      <td>4446.666667</td>\n      <td>3954.358974</td>\n      <td>5036.923077</td>\n      <td>3830.769231</td>\n      <td>4044.102564</td>\n      <td>4189.743590</td>\n      <td>...</td>\n      <td>4076.923077</td>\n      <td>1574.0</td>\n      <td>1714.0</td>\n      <td>242.433</td>\n      <td>0.031277</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>124.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>4448.717949</td>\n      <td>3952.820513</td>\n      <td>5034.358974</td>\n      <td>3833.333333</td>\n      <td>4046.153846</td>\n      <td>4187.692308</td>\n      <td>...</td>\n      <td>4068.205128</td>\n      <td>1577.0</td>\n      <td>1713.0</td>\n      <td>242.440</td>\n      <td>0.031277</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>408971</th>\n      <td>408971</td>\n      <td>48.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>4449.230769</td>\n      <td>3960.000000</td>\n      <td>5003.076923</td>\n      <td>3832.820513</td>\n      <td>4048.205128</td>\n      <td>4270.769231</td>\n      <td>...</td>\n      <td>4272.820513</td>\n      <td>1574.0</td>\n      <td>1739.0</td>\n      <td>3440.381</td>\n      <td>3197.802734</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>408972</th>\n      <td>408972</td>\n      <td>49.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>4448.205128</td>\n      <td>3959.487179</td>\n      <td>5008.717949</td>\n      <td>3833.846154</td>\n      <td>4045.641026</td>\n      <td>4276.410256</td>\n      <td>...</td>\n      <td>4278.974359</td>\n      <td>1574.0</td>\n      <td>1740.0</td>\n      <td>3440.389</td>\n      <td>3197.802734</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>408973</th>\n      <td>408973</td>\n      <td>50.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>4445.641026</td>\n      <td>3960.000000</td>\n      <td>5014.871795</td>\n      <td>3831.794872</td>\n      <td>4046.666667</td>\n      <td>4273.333333</td>\n      <td>...</td>\n      <td>4275.897436</td>\n      <td>1575.0</td>\n      <td>1740.0</td>\n      <td>3440.397</td>\n      <td>3197.802734</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>408974</th>\n      <td>408974</td>\n      <td>51.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>4446.666667</td>\n      <td>3959.487179</td>\n      <td>5024.102564</td>\n      <td>3828.717949</td>\n      <td>4045.128205</td>\n      <td>4274.871795</td>\n      <td>...</td>\n      <td>4272.820513</td>\n      <td>1575.0</td>\n      <td>1740.0</td>\n      <td>3440.405</td>\n      <td>3197.802734</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>408975</th>\n      <td>408975</td>\n      <td>52.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>4445.641026</td>\n      <td>3960.512821</td>\n      <td>5029.743590</td>\n      <td>3828.205128</td>\n      <td>4038.461538</td>\n      <td>4281.025641</td>\n      <td>...</td>\n      <td>4278.461538</td>\n      <td>1577.0</td>\n      <td>1738.0</td>\n      <td>3440.412</td>\n      <td>3197.802734</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n<p>408976 rows × 27 columns</p>\n</div>"},"metadata":{}}],"execution_count":23},{"cell_type":"code","source":"y","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-13T16:39:59.420158Z","iopub.execute_input":"2025-04-13T16:39:59.420386Z","iopub.status.idle":"2025-04-13T16:39:59.426014Z","shell.execute_reply.started":"2025-04-13T16:39:59.420362Z","shell.execute_reply":"2025-04-13T16:39:59.425181Z"}},"outputs":[{"execution_count":24,"output_type":"execute_result","data":{"text/plain":"array([[1., 0., 0.],\n       [1., 0., 0.],\n       [1., 0., 0.],\n       ...,\n       [0., 1., 0.],\n       [0., 1., 0.],\n       [0., 1., 0.]])"},"metadata":{}}],"execution_count":24},{"cell_type":"code","source":"X.shape","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-13T16:39:59.427003Z","iopub.execute_input":"2025-04-13T16:39:59.427273Z","iopub.status.idle":"2025-04-13T16:39:59.435153Z","shell.execute_reply.started":"2025-04-13T16:39:59.427230Z","shell.execute_reply":"2025-04-13T16:39:59.434431Z"}},"outputs":[{"execution_count":25,"output_type":"execute_result","data":{"text/plain":"(24418, 512, 14, 1)"},"metadata":{}}],"execution_count":25},{"cell_type":"markdown","source":"# Helper functions","metadata":{}},{"cell_type":"code","source":"def f1_score(precision, recall):\n    return 2 * ((precision * recall) / (precision + recall))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-13T16:39:59.436017Z","iopub.execute_input":"2025-04-13T16:39:59.436266Z","iopub.status.idle":"2025-04-13T16:39:59.443449Z","shell.execute_reply.started":"2025-04-13T16:39:59.436242Z","shell.execute_reply":"2025-04-13T16:39:59.442584Z"}},"outputs":[],"execution_count":26},{"cell_type":"code","source":"# Evaluate the model\ndef evaluate_model(model):\n    results = model.evaluate(X_test, y_test)\n    test_loss, test_accuracy, test_precision, test_recall, test_auc = results\n    test_f1 = f1_score(test_precision, test_recall)\n    # Print results\n    print(f\"Test Loss: {test_loss:.4f}\")\n    print(f\"Test Accuracy: {test_accuracy:.4f}\")\n    print(f\"Test Precision: {test_precision:.4f}\")\n    print(f\"Test Recall: {test_recall:.4f}\")\n    print(f\"Test AUC: {test_auc:.4f}\")\n    print(f\"Test F1: {test_f1:.4f}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-13T16:39:59.444399Z","iopub.execute_input":"2025-04-13T16:39:59.444982Z","iopub.status.idle":"2025-04-13T16:39:59.453134Z","shell.execute_reply.started":"2025-04-13T16:39:59.444944Z","shell.execute_reply":"2025-04-13T16:39:59.452492Z"}},"outputs":[],"execution_count":27},{"cell_type":"markdown","source":"# Model","metadata":{}},{"cell_type":"markdown","source":"****13/04/2025","metadata":{}},{"cell_type":"code","source":"import tensorflow as tf\nimport gc\n\n# Force garbage collection\ngc.collect()\n\n# Force TensorFlow to use CPU\nwith tf.device('/CPU:0'):\n    # Simple CNN model for EEG\n    from tensorflow.keras.models import Sequential\n    from tensorflow.keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D\n    from tensorflow.keras.callbacks import EarlyStopping\n    from tensorflow.keras.metrics import Precision, Recall, AUC\n\n    model = Sequential([\n        # First convolutional layer\n        Conv2D(32, (1, 14), activation='relu', input_shape=(SAMPLE_LENGTH_HZ, 14, 1)),\n        MaxPooling2D(pool_size=(4, 1)),\n        Dropout(0.3),\n        \n        # Second convolutional layer\n        Conv2D(64, (5, 1), activation='relu', padding='same'),\n        MaxPooling2D(pool_size=(4, 1)),\n        Dropout(0.4),\n        \n        # Classification layers\n        Flatten(),\n        Dense(128, activation='relu'),\n        Dropout(0.5),\n        Dense(3, activation='softmax')\n    ])\n\n    # Compile the model\n    model.compile(\n        optimizer='adam',\n        loss='categorical_crossentropy',\n        metrics=[\n            'accuracy',\n            Precision(name='precision'),\n            Recall(name='recall'),\n            AUC(name='auc')\n        ]\n    )\n\n    # Define callbacks\n    early_stopping = EarlyStopping(\n        monitor='val_loss',\n        patience=15,\n        restore_best_weights=True\n    )\n\n    # Train on CPU\n    history = model.fit(\n        X_train, y_train,\n        validation_data=(X_test, y_test),\n        epochs=100,\n        batch_size=32,  # Can use larger batch size on CPU\n        callbacks=[early_stopping]\n    )\n\n    # Evaluate using your function\n    evaluate_model(model)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-13T16:54:18.954662Z","iopub.execute_input":"2025-04-13T16:54:18.955030Z","iopub.status.idle":"2025-04-13T17:09:59.640806Z","shell.execute_reply.started":"2025-04-13T16:54:18.954999Z","shell.execute_reply":"2025-04-13T17:09:59.639926Z"}},"outputs":[{"name":"stdout","text":"Epoch 1/100\n","output_type":"stream"},{"name":"stderr","text":"I0000 00:00:1744563261.911321     122 service.cc:145] XLA service 0x7e980c003010 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\nI0000 00:00:1744563261.911369     122 service.cc:153]   StreamExecutor device (0): Host, Default Version\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m611/611\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 29ms/step - accuracy: 0.7074 - auc: 0.8658 - loss: 0.7146 - precision: 0.7843 - recall: 0.6079 - val_accuracy: 0.7662 - val_auc: 0.9220 - val_loss: 0.5463 - val_precision: 0.8436 - val_recall: 0.6536\nEpoch 2/100\n\u001b[1m611/611\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 26ms/step - accuracy: 0.7747 - auc: 0.9218 - loss: 0.5467 - precision: 0.8228 - recall: 0.7022 - val_accuracy: 0.7852 - val_auc: 0.9365 - val_loss: 0.5121 - val_precision: 0.8483 - val_recall: 0.7088\nEpoch 3/100\n\u001b[1m611/611\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 25ms/step - accuracy: 0.7991 - auc: 0.9369 - loss: 0.4830 - precision: 0.8331 - recall: 0.7460 - val_accuracy: 0.7807 - val_auc: 0.9300 - val_loss: 0.5294 - val_precision: 0.8324 - val_recall: 0.7230\nEpoch 4/100\n\u001b[1m611/611\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 26ms/step - accuracy: 0.8008 - auc: 0.9412 - loss: 0.4616 - precision: 0.8302 - recall: 0.7565 - val_accuracy: 0.8188 - val_auc: 0.9513 - val_loss: 0.4573 - val_precision: 0.8718 - val_recall: 0.7365\nEpoch 5/100\n\u001b[1m611/611\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 25ms/step - accuracy: 0.8181 - auc: 0.9499 - loss: 0.4274 - precision: 0.8441 - recall: 0.7836 - val_accuracy: 0.8161 - val_auc: 0.9493 - val_loss: 0.4688 - val_precision: 0.8727 - val_recall: 0.7400\nEpoch 6/100\n\u001b[1m611/611\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 25ms/step - accuracy: 0.8323 - auc: 0.9562 - loss: 0.4020 - precision: 0.8558 - recall: 0.7983 - val_accuracy: 0.8153 - val_auc: 0.9474 - val_loss: 0.4692 - val_precision: 0.8659 - val_recall: 0.7471\nEpoch 7/100\n\u001b[1m611/611\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 25ms/step - accuracy: 0.8330 - auc: 0.9576 - loss: 0.3931 - precision: 0.8547 - recall: 0.8071 - val_accuracy: 0.8172 - val_auc: 0.9510 - val_loss: 0.4496 - val_precision: 0.8566 - val_recall: 0.7731\nEpoch 8/100\n\u001b[1m611/611\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 25ms/step - accuracy: 0.8389 - auc: 0.9604 - loss: 0.3789 - precision: 0.8575 - recall: 0.8155 - val_accuracy: 0.8305 - val_auc: 0.9572 - val_loss: 0.4060 - val_precision: 0.8660 - val_recall: 0.8008\nEpoch 9/100\n\u001b[1m611/611\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 25ms/step - accuracy: 0.8461 - auc: 0.9630 - loss: 0.3673 - precision: 0.8683 - recall: 0.8241 - val_accuracy: 0.8329 - val_auc: 0.9583 - val_loss: 0.4070 - val_precision: 0.8627 - val_recall: 0.7950\nEpoch 10/100\n\u001b[1m611/611\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 25ms/step - accuracy: 0.8582 - auc: 0.9660 - loss: 0.3508 - precision: 0.8741 - recall: 0.8388 - val_accuracy: 0.8178 - val_auc: 0.9504 - val_loss: 0.4314 - val_precision: 0.8518 - val_recall: 0.7826\nEpoch 11/100\n\u001b[1m611/611\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 25ms/step - accuracy: 0.8476 - auc: 0.9657 - loss: 0.3495 - precision: 0.8652 - recall: 0.8284 - val_accuracy: 0.8436 - val_auc: 0.9637 - val_loss: 0.3721 - val_precision: 0.8670 - val_recall: 0.8129\nEpoch 12/100\n\u001b[1m611/611\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 26ms/step - accuracy: 0.8566 - auc: 0.9675 - loss: 0.3419 - precision: 0.8746 - recall: 0.8395 - val_accuracy: 0.8499 - val_auc: 0.9648 - val_loss: 0.3665 - val_precision: 0.8739 - val_recall: 0.8245\nEpoch 13/100\n\u001b[1m611/611\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 25ms/step - accuracy: 0.8627 - auc: 0.9700 - loss: 0.3273 - precision: 0.8762 - recall: 0.8482 - val_accuracy: 0.8516 - val_auc: 0.9628 - val_loss: 0.3834 - val_precision: 0.8798 - val_recall: 0.8182\nEpoch 14/100\n\u001b[1m611/611\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 26ms/step - accuracy: 0.8650 - auc: 0.9708 - loss: 0.3251 - precision: 0.8775 - recall: 0.8501 - val_accuracy: 0.8417 - val_auc: 0.9615 - val_loss: 0.3832 - val_precision: 0.8737 - val_recall: 0.8090\nEpoch 15/100\n\u001b[1m611/611\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 25ms/step - accuracy: 0.8719 - auc: 0.9733 - loss: 0.3073 - precision: 0.8844 - recall: 0.8580 - val_accuracy: 0.8471 - val_auc: 0.9630 - val_loss: 0.3719 - val_precision: 0.8651 - val_recall: 0.8262\nEpoch 16/100\n\u001b[1m611/611\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 25ms/step - accuracy: 0.8692 - auc: 0.9727 - loss: 0.3140 - precision: 0.8820 - recall: 0.8543 - val_accuracy: 0.8344 - val_auc: 0.9555 - val_loss: 0.4050 - val_precision: 0.8530 - val_recall: 0.8176\nEpoch 17/100\n\u001b[1m611/611\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 26ms/step - accuracy: 0.8705 - auc: 0.9738 - loss: 0.3056 - precision: 0.8845 - recall: 0.8573 - val_accuracy: 0.8432 - val_auc: 0.9616 - val_loss: 0.3824 - val_precision: 0.8658 - val_recall: 0.8217\nEpoch 18/100\n\u001b[1m611/611\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 25ms/step - accuracy: 0.8708 - auc: 0.9739 - loss: 0.3070 - precision: 0.8850 - recall: 0.8582 - val_accuracy: 0.8550 - val_auc: 0.9646 - val_loss: 0.3627 - val_precision: 0.8719 - val_recall: 0.8307\nEpoch 19/100\n\u001b[1m611/611\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 25ms/step - accuracy: 0.8813 - auc: 0.9753 - loss: 0.3030 - precision: 0.8926 - recall: 0.8672 - val_accuracy: 0.8425 - val_auc: 0.9595 - val_loss: 0.3858 - val_precision: 0.8583 - val_recall: 0.8210\nEpoch 20/100\n\u001b[1m611/611\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 25ms/step - accuracy: 0.8825 - auc: 0.9777 - loss: 0.2814 - precision: 0.8945 - recall: 0.8698 - val_accuracy: 0.8602 - val_auc: 0.9664 - val_loss: 0.3605 - val_precision: 0.8751 - val_recall: 0.8423\nEpoch 21/100\n\u001b[1m611/611\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 25ms/step - accuracy: 0.8808 - auc: 0.9769 - loss: 0.2881 - precision: 0.8928 - recall: 0.8699 - val_accuracy: 0.8524 - val_auc: 0.9637 - val_loss: 0.3673 - val_precision: 0.8663 - val_recall: 0.8292\nEpoch 22/100\n\u001b[1m611/611\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 25ms/step - accuracy: 0.8827 - auc: 0.9773 - loss: 0.2854 - precision: 0.8934 - recall: 0.8717 - val_accuracy: 0.8616 - val_auc: 0.9690 - val_loss: 0.3401 - val_precision: 0.8783 - val_recall: 0.8440\nEpoch 23/100\n\u001b[1m611/611\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 25ms/step - accuracy: 0.8870 - auc: 0.9793 - loss: 0.2739 - precision: 0.8979 - recall: 0.8771 - val_accuracy: 0.8683 - val_auc: 0.9694 - val_loss: 0.3409 - val_precision: 0.8838 - val_recall: 0.8452\nEpoch 24/100\n\u001b[1m611/611\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 25ms/step - accuracy: 0.8891 - auc: 0.9792 - loss: 0.2705 - precision: 0.8998 - recall: 0.8804 - val_accuracy: 0.8430 - val_auc: 0.9620 - val_loss: 0.3785 - val_precision: 0.8573 - val_recall: 0.8280\nEpoch 25/100\n\u001b[1m611/611\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 25ms/step - accuracy: 0.8844 - auc: 0.9784 - loss: 0.2774 - precision: 0.8942 - recall: 0.8729 - val_accuracy: 0.8475 - val_auc: 0.9615 - val_loss: 0.3823 - val_precision: 0.8631 - val_recall: 0.8325\nEpoch 26/100\n\u001b[1m611/611\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 25ms/step - accuracy: 0.8883 - auc: 0.9787 - loss: 0.2755 - precision: 0.8971 - recall: 0.8788 - val_accuracy: 0.8753 - val_auc: 0.9717 - val_loss: 0.3292 - val_precision: 0.8895 - val_recall: 0.8600\nEpoch 27/100\n\u001b[1m611/611\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 25ms/step - accuracy: 0.8895 - auc: 0.9792 - loss: 0.2698 - precision: 0.8970 - recall: 0.8805 - val_accuracy: 0.8495 - val_auc: 0.9645 - val_loss: 0.3619 - val_precision: 0.8628 - val_recall: 0.8382\nEpoch 28/100\n\u001b[1m611/611\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 25ms/step - accuracy: 0.8932 - auc: 0.9804 - loss: 0.2641 - precision: 0.9014 - recall: 0.8839 - val_accuracy: 0.8602 - val_auc: 0.9688 - val_loss: 0.3411 - val_precision: 0.8790 - val_recall: 0.8405\nEpoch 29/100\n\u001b[1m611/611\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 25ms/step - accuracy: 0.8899 - auc: 0.9800 - loss: 0.2672 - precision: 0.8994 - recall: 0.8789 - val_accuracy: 0.8624 - val_auc: 0.9703 - val_loss: 0.3362 - val_precision: 0.8723 - val_recall: 0.8534\nEpoch 30/100\n\u001b[1m611/611\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 25ms/step - accuracy: 0.8955 - auc: 0.9828 - loss: 0.2454 - precision: 0.9038 - recall: 0.8883 - val_accuracy: 0.8522 - val_auc: 0.9658 - val_loss: 0.3568 - val_precision: 0.8624 - val_recall: 0.8405\nEpoch 31/100\n\u001b[1m611/611\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 26ms/step - accuracy: 0.8966 - auc: 0.9819 - loss: 0.2560 - precision: 0.9058 - recall: 0.8872 - val_accuracy: 0.8700 - val_auc: 0.9707 - val_loss: 0.3320 - val_precision: 0.8811 - val_recall: 0.8585\nEpoch 32/100\n\u001b[1m611/611\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 25ms/step - accuracy: 0.8939 - auc: 0.9814 - loss: 0.2569 - precision: 0.9014 - recall: 0.8858 - val_accuracy: 0.8643 - val_auc: 0.9665 - val_loss: 0.3578 - val_precision: 0.8753 - val_recall: 0.8505\nEpoch 33/100\n\u001b[1m611/611\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 26ms/step - accuracy: 0.8956 - auc: 0.9822 - loss: 0.2500 - precision: 0.9034 - recall: 0.8874 - val_accuracy: 0.8587 - val_auc: 0.9680 - val_loss: 0.3460 - val_precision: 0.8744 - val_recall: 0.8436\nEpoch 34/100\n\u001b[1m611/611\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 26ms/step - accuracy: 0.9030 - auc: 0.9835 - loss: 0.2412 - precision: 0.9114 - recall: 0.8936 - val_accuracy: 0.8589 - val_auc: 0.9663 - val_loss: 0.3530 - val_precision: 0.8701 - val_recall: 0.8475\nEpoch 35/100\n\u001b[1m611/611\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 25ms/step - accuracy: 0.8998 - auc: 0.9829 - loss: 0.2462 - precision: 0.9060 - recall: 0.8907 - val_accuracy: 0.8649 - val_auc: 0.9675 - val_loss: 0.3482 - val_precision: 0.8768 - val_recall: 0.8462\nEpoch 36/100\n\u001b[1m611/611\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 26ms/step - accuracy: 0.9025 - auc: 0.9841 - loss: 0.2360 - precision: 0.9098 - recall: 0.8953 - val_accuracy: 0.8155 - val_auc: 0.9494 - val_loss: 0.4530 - val_precision: 0.8248 - val_recall: 0.8051\nEpoch 37/100\n\u001b[1m611/611\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 26ms/step - accuracy: 0.8993 - auc: 0.9833 - loss: 0.2449 - precision: 0.9057 - recall: 0.8912 - val_accuracy: 0.8452 - val_auc: 0.9637 - val_loss: 0.3685 - val_precision: 0.8598 - val_recall: 0.8286\nEpoch 38/100\n\u001b[1m611/611\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 26ms/step - accuracy: 0.9030 - auc: 0.9837 - loss: 0.2373 - precision: 0.9110 - recall: 0.8954 - val_accuracy: 0.8618 - val_auc: 0.9671 - val_loss: 0.3499 - val_precision: 0.8729 - val_recall: 0.8509\nEpoch 39/100\n\u001b[1m611/611\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 25ms/step - accuracy: 0.9068 - auc: 0.9847 - loss: 0.2309 - precision: 0.9146 - recall: 0.8994 - val_accuracy: 0.8643 - val_auc: 0.9712 - val_loss: 0.3263 - val_precision: 0.8749 - val_recall: 0.8524\nEpoch 40/100\n\u001b[1m611/611\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 25ms/step - accuracy: 0.9064 - auc: 0.9847 - loss: 0.2347 - precision: 0.9137 - recall: 0.9004 - val_accuracy: 0.8708 - val_auc: 0.9720 - val_loss: 0.3320 - val_precision: 0.8859 - val_recall: 0.8565\nEpoch 41/100\n\u001b[1m611/611\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 26ms/step - accuracy: 0.9056 - auc: 0.9844 - loss: 0.2328 - precision: 0.9137 - recall: 0.8978 - val_accuracy: 0.8776 - val_auc: 0.9717 - val_loss: 0.3244 - val_precision: 0.8838 - val_recall: 0.8673\nEpoch 42/100\n\u001b[1m611/611\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 26ms/step - accuracy: 0.9024 - auc: 0.9838 - loss: 0.2439 - precision: 0.9094 - recall: 0.8960 - val_accuracy: 0.8450 - val_auc: 0.9610 - val_loss: 0.3781 - val_precision: 0.8619 - val_recall: 0.8278\nEpoch 43/100\n\u001b[1m611/611\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 26ms/step - accuracy: 0.9093 - auc: 0.9857 - loss: 0.2247 - precision: 0.9162 - recall: 0.9031 - val_accuracy: 0.8659 - val_auc: 0.9692 - val_loss: 0.3410 - val_precision: 0.8758 - val_recall: 0.8546\nEpoch 44/100\n\u001b[1m611/611\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 25ms/step - accuracy: 0.9124 - auc: 0.9866 - loss: 0.2150 - precision: 0.9187 - recall: 0.9062 - val_accuracy: 0.8677 - val_auc: 0.9698 - val_loss: 0.3405 - val_precision: 0.8805 - val_recall: 0.8540\nEpoch 45/100\n\u001b[1m611/611\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 26ms/step - accuracy: 0.9063 - auc: 0.9852 - loss: 0.2284 - precision: 0.9142 - recall: 0.8987 - val_accuracy: 0.8769 - val_auc: 0.9731 - val_loss: 0.3165 - val_precision: 0.8911 - val_recall: 0.8628\nEpoch 46/100\n\u001b[1m611/611\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 25ms/step - accuracy: 0.9114 - auc: 0.9862 - loss: 0.2212 - precision: 0.9191 - recall: 0.9044 - val_accuracy: 0.8718 - val_auc: 0.9710 - val_loss: 0.3299 - val_precision: 0.8827 - val_recall: 0.8632\nEpoch 47/100\n\u001b[1m611/611\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 26ms/step - accuracy: 0.9126 - auc: 0.9859 - loss: 0.2240 - precision: 0.9184 - recall: 0.9047 - val_accuracy: 0.8712 - val_auc: 0.9716 - val_loss: 0.3306 - val_precision: 0.8835 - val_recall: 0.8589\nEpoch 48/100\n\u001b[1m611/611\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 25ms/step - accuracy: 0.9109 - auc: 0.9860 - loss: 0.2215 - precision: 0.9180 - recall: 0.9040 - val_accuracy: 0.8688 - val_auc: 0.9707 - val_loss: 0.3366 - val_precision: 0.8820 - val_recall: 0.8597\nEpoch 49/100\n\u001b[1m611/611\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 25ms/step - accuracy: 0.9191 - auc: 0.9876 - loss: 0.2076 - precision: 0.9248 - recall: 0.9116 - val_accuracy: 0.8737 - val_auc: 0.9717 - val_loss: 0.3278 - val_precision: 0.8879 - val_recall: 0.8612\nEpoch 50/100\n\u001b[1m611/611\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 25ms/step - accuracy: 0.9149 - auc: 0.9859 - loss: 0.2266 - precision: 0.9212 - recall: 0.9070 - val_accuracy: 0.8706 - val_auc: 0.9711 - val_loss: 0.3297 - val_precision: 0.8769 - val_recall: 0.8638\nEpoch 51/100\n\u001b[1m611/611\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 26ms/step - accuracy: 0.9188 - auc: 0.9871 - loss: 0.2131 - precision: 0.9235 - recall: 0.9131 - val_accuracy: 0.8733 - val_auc: 0.9717 - val_loss: 0.3306 - val_precision: 0.8806 - val_recall: 0.8657\nEpoch 52/100\n\u001b[1m611/611\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 25ms/step - accuracy: 0.9122 - auc: 0.9868 - loss: 0.2141 - precision: 0.9183 - recall: 0.9057 - val_accuracy: 0.8751 - val_auc: 0.9717 - val_loss: 0.3235 - val_precision: 0.8833 - val_recall: 0.8667\nEpoch 53/100\n\u001b[1m611/611\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 26ms/step - accuracy: 0.9184 - auc: 0.9871 - loss: 0.2116 - precision: 0.9242 - recall: 0.9138 - val_accuracy: 0.8585 - val_auc: 0.9678 - val_loss: 0.3570 - val_precision: 0.8698 - val_recall: 0.8509\nEpoch 54/100\n\u001b[1m611/611\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 26ms/step - accuracy: 0.9171 - auc: 0.9871 - loss: 0.2157 - precision: 0.9232 - recall: 0.9123 - val_accuracy: 0.8808 - val_auc: 0.9721 - val_loss: 0.3458 - val_precision: 0.8878 - val_recall: 0.8749\nEpoch 55/100\n\u001b[1m611/611\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 26ms/step - accuracy: 0.9174 - auc: 0.9881 - loss: 0.2070 - precision: 0.9231 - recall: 0.9128 - val_accuracy: 0.8825 - val_auc: 0.9733 - val_loss: 0.3263 - val_precision: 0.8900 - val_recall: 0.8747\nEpoch 56/100\n\u001b[1m611/611\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 25ms/step - accuracy: 0.9163 - auc: 0.9867 - loss: 0.2173 - precision: 0.9217 - recall: 0.9095 - val_accuracy: 0.8669 - val_auc: 0.9702 - val_loss: 0.3381 - val_precision: 0.8752 - val_recall: 0.8583\nEpoch 57/100\n\u001b[1m611/611\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 26ms/step - accuracy: 0.9218 - auc: 0.9891 - loss: 0.1942 - precision: 0.9278 - recall: 0.9149 - val_accuracy: 0.8698 - val_auc: 0.9707 - val_loss: 0.3398 - val_precision: 0.8772 - val_recall: 0.8616\nEpoch 58/100\n\u001b[1m611/611\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 25ms/step - accuracy: 0.9087 - auc: 0.9855 - loss: 0.2265 - precision: 0.9123 - recall: 0.9040 - val_accuracy: 0.8733 - val_auc: 0.9712 - val_loss: 0.3346 - val_precision: 0.8815 - val_recall: 0.8655\nEpoch 59/100\n\u001b[1m611/611\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 26ms/step - accuracy: 0.9245 - auc: 0.9890 - loss: 0.1951 - precision: 0.9300 - recall: 0.9195 - val_accuracy: 0.8434 - val_auc: 0.9607 - val_loss: 0.3905 - val_precision: 0.8554 - val_recall: 0.8344\nEpoch 60/100\n\u001b[1m611/611\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 25ms/step - accuracy: 0.9175 - auc: 0.9876 - loss: 0.2095 - precision: 0.9222 - recall: 0.9129 - val_accuracy: 0.8696 - val_auc: 0.9703 - val_loss: 0.3397 - val_precision: 0.8775 - val_recall: 0.8622\n\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8791 - auc: 0.9738 - loss: 0.3141 - precision: 0.8917 - recall: 0.8694\nTest Loss: 0.3165\nTest Accuracy: 0.8769\nTest Precision: 0.8911\nTest Recall: 0.8628\nTest AUC: 0.9731\nTest F1: 0.8767\n","output_type":"stream"}],"execution_count":30},{"cell_type":"code","source":"import gc\n\n# Force garbage collection\ngc.collect()\n\n# Force TensorFlow to use CPU\nwith tf.device('/CPU:0'):\n    # Simple CNN model for EEG\n    from tensorflow.keras.models import Sequential\n    from tensorflow.keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D\n    from tensorflow.keras.callbacks import EarlyStopping\n    from tensorflow.keras.metrics import Precision, Recall, AUC\n\n    model = Sequential([\n        # First convolutional layer\n        Conv2D(32, (1, 14), activation='relu', input_shape=(SAMPLE_LENGTH_HZ, 14, 1)),\n        MaxPooling2D(pool_size=(4, 1)),\n        Dropout(0.3),\n        \n        # Second convolutional layer\n        Conv2D(64, (5, 1), activation='relu', padding='same'),\n        MaxPooling2D(pool_size=(4, 1)),\n        Dropout(0.4),\n        \n        # Classification layers\n        Flatten(),\n        Dense(128, activation='relu'),\n        Dropout(0.5),\n        Dense(3, activation='softmax')\n    ])\n\n    # Compile the model\n    model.compile(\n        optimizer='adam',\n        loss='categorical_crossentropy',\n        metrics=[\n            'accuracy',\n            Precision(name='precision'),\n            Recall(name='recall'),\n            AUC(name='auc')\n        ]\n    )\n\n    # Define callbacks\n    # early_stopping = EarlyStopping(\n    #     monitor='val_loss',\n    #     patience=15,\n    #     restore_best_weights=True\n    # )\n\n    # Train on CPU\n    history = model.fit(\n        X_train, y_train,\n        validation_data=(X_test, y_test),\n        epochs=100,\n        batch_size=32,  # Can use larger batch size on CPU\n    )\n\n    # Evaluate using your function\n    evaluate_model(model)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-13T17:41:14.513408Z","iopub.execute_input":"2025-04-13T17:41:14.513785Z"}},"outputs":[{"name":"stdout","text":"Epoch 1/100\n\u001b[1m611/611\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 30ms/step - accuracy: 0.7089 - auc: 0.8655 - loss: 0.7140 - precision: 0.7826 - recall: 0.6065 - val_accuracy: 0.7670 - val_auc: 0.9167 - val_loss: 0.6390 - val_precision: 0.8874 - val_recall: 0.5565\nEpoch 2/100\n\u001b[1m611/611\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 25ms/step - accuracy: 0.7611 - auc: 0.9167 - loss: 0.5665 - precision: 0.8226 - recall: 0.6788 - val_accuracy: 0.7928 - val_auc: 0.9380 - val_loss: 0.4873 - val_precision: 0.8310 - val_recall: 0.7369\nEpoch 3/100\n\u001b[1m611/611\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 26ms/step - accuracy: 0.7917 - auc: 0.9333 - loss: 0.4978 - precision: 0.8283 - recall: 0.7365 - val_accuracy: 0.8127 - val_auc: 0.9475 - val_loss: 0.4572 - val_precision: 0.8635 - val_recall: 0.7486\nEpoch 4/100\n\u001b[1m611/611\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 25ms/step - accuracy: 0.8076 - auc: 0.9428 - loss: 0.4591 - precision: 0.8426 - recall: 0.7619 - val_accuracy: 0.8055 - val_auc: 0.9394 - val_loss: 0.4954 - val_precision: 0.8603 - val_recall: 0.7088\nEpoch 5/100\n\u001b[1m611/611\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 26ms/step - accuracy: 0.8111 - auc: 0.9469 - loss: 0.4402 - precision: 0.8434 - recall: 0.7683 - val_accuracy: 0.8262 - val_auc: 0.9529 - val_loss: 0.4339 - val_precision: 0.8710 - val_recall: 0.7701\nEpoch 6/100\n\u001b[1m611/611\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 25ms/step - accuracy: 0.8276 - auc: 0.9538 - loss: 0.4109 - precision: 0.8545 - recall: 0.7963 - val_accuracy: 0.8278 - val_auc: 0.9534 - val_loss: 0.4422 - val_precision: 0.8654 - val_recall: 0.7729\nEpoch 7/100\n\u001b[1m611/611\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 26ms/step - accuracy: 0.8373 - auc: 0.9576 - loss: 0.3940 - precision: 0.8586 - recall: 0.8064 - val_accuracy: 0.8370 - val_auc: 0.9566 - val_loss: 0.4249 - val_precision: 0.8806 - val_recall: 0.7789\nEpoch 8/100\n\u001b[1m611/611\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 25ms/step - accuracy: 0.8393 - auc: 0.9587 - loss: 0.3899 - precision: 0.8632 - recall: 0.8085 - val_accuracy: 0.8446 - val_auc: 0.9590 - val_loss: 0.4184 - val_precision: 0.8816 - val_recall: 0.7854\nEpoch 9/100\n\u001b[1m611/611\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 25ms/step - accuracy: 0.8445 - auc: 0.9618 - loss: 0.3765 - precision: 0.8698 - recall: 0.8161 - val_accuracy: 0.8425 - val_auc: 0.9588 - val_loss: 0.4042 - val_precision: 0.8720 - val_recall: 0.8020\nEpoch 10/100\n\u001b[1m611/611\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 25ms/step - accuracy: 0.8490 - auc: 0.9637 - loss: 0.3643 - precision: 0.8695 - recall: 0.8235 - val_accuracy: 0.8460 - val_auc: 0.9616 - val_loss: 0.3932 - val_precision: 0.8724 - val_recall: 0.8116\nEpoch 11/100\n\u001b[1m611/611\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 25ms/step - accuracy: 0.8516 - auc: 0.9658 - loss: 0.3511 - precision: 0.8711 - recall: 0.8291 - val_accuracy: 0.8483 - val_auc: 0.9610 - val_loss: 0.4001 - val_precision: 0.8800 - val_recall: 0.8065\nEpoch 12/100\n\u001b[1m611/611\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 26ms/step - accuracy: 0.8605 - auc: 0.9677 - loss: 0.3432 - precision: 0.8781 - recall: 0.8373 - val_accuracy: 0.8573 - val_auc: 0.9639 - val_loss: 0.3782 - val_precision: 0.8806 - val_recall: 0.8182\nEpoch 13/100\n\u001b[1m611/611\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 25ms/step - accuracy: 0.8574 - auc: 0.9682 - loss: 0.3416 - precision: 0.8744 - recall: 0.8389 - val_accuracy: 0.8479 - val_auc: 0.9618 - val_loss: 0.3898 - val_precision: 0.8728 - val_recall: 0.8188\nEpoch 14/100\n\u001b[1m611/611\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 26ms/step - accuracy: 0.8613 - auc: 0.9689 - loss: 0.3355 - precision: 0.8761 - recall: 0.8405 - val_accuracy: 0.8538 - val_auc: 0.9655 - val_loss: 0.3763 - val_precision: 0.8774 - val_recall: 0.8253\nEpoch 15/100\n\u001b[1m406/611\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 24ms/step - accuracy: 0.8697 - auc: 0.9721 - loss: 0.3184 - precision: 0.8867 - recall: 0.8490","output_type":"stream"}],"execution_count":null},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Dropout, Reshape\nfrom tensorflow.keras.layers import MultiHeadAttention, LayerNormalization, Dense, GlobalAveragePooling1D\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.metrics import Precision, Recall, AUC\nimport gc\nfrom tensorflow.keras import backend as K\n\n# Clear memory if re-running\ngc.collect()\nK.clear_session()\n\nwith tf.device('/CPU:0'):\n    inp = Input(shape=(SAMPLE_LENGTH_HZ, 14, 1))  # EEG input shape\n\n    # CNN block\n    x = Conv2D(32, (1, 3), activation='relu', padding='same')(inp)\n    x = MaxPooling2D(pool_size=(2, 1))(x)\n    x = Dropout(0.2)(x)\n\n    x = Conv2D(64, (1, 3), activation='relu', padding='same')(x)\n    x = MaxPooling2D(pool_size=(2, 1))(x)\n    x = Dropout(0.3)(x)\n\n    # Reshape for transformer\n    x = Reshape((x.shape[1], x.shape[2] * x.shape[3]))(x)\n\n    # Transformer encoder block\n    attn = MultiHeadAttention(num_heads=1, key_dim=16)(x, x)\n    attn = LayerNormalization()(attn)\n\n    ffn = Dense(64, activation='relu')(attn)\n    ffn = LayerNormalization()(ffn)\n\n    x = GlobalAveragePooling1D()(ffn)\n\n    # Classifier\n    x = Dense(64, activation='relu')(x)\n    x = Dropout(0.4)(x)\n    out = Dense(3, activation='softmax')(x)\n\n    model = Model(inputs=inp, outputs=out)\n\n    model.compile(\n        optimizer=Adam(),\n        loss='categorical_crossentropy',\n        metrics=['accuracy', Precision(name='precision'), Recall(name='recall'), AUC(name='auc')]\n    )\n\n    model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=100, batch_size=16)\n\n    evaluate_model(model)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"End of 13/04/2025","metadata":{}},{"cell_type":"markdown","source":"## CNN","metadata":{}},{"cell_type":"code","source":"# Define the CNN model\nmodel = Sequential([\n    Conv2D(40, (1, 14), activation='relu', input_shape=(SAMPLE_LENGTH_HZ, 14, 1)),\n    Conv2D(40, (1, 1), activation='relu'),\n    AveragePooling2D(pool_size=(15, 1)),\n    Dropout(0.5),\n    Flatten(),\n    Dense(80, activation='relu'),\n    Dropout(0.5),\n    Dense(3, activation='softmax')  # 3 classes for classification\n])\n\n# Compile the model\nmodel.compile(\n    optimizer='adam',\n    loss='categorical_crossentropy',\n    metrics=[\n        'accuracy',             # Include default accuracy metric\n        Precision(name='precision'),\n        Recall(name='recall'),\n        AUC(name='auc')         # Add AUC metric\n    ]\n)\n# Define EarlyStopping\nearly_stopping = EarlyStopping(\n    monitor='val_loss',        # Monitor validation loss\n    patience=10,               # Stop after 10 epochs with no improvement\n    restore_best_weights=True  # Restore the best weights\n)\n\n\n","metadata":{"trusted":true,"scrolled":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"plot_model(model, to_file='model_architecture.png', show_shapes=True, show_layer_names=True)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model.summary()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Train the model\nhistory = model.fit(\n    X_train, y_train,\n    validation_data=(X_test, y_test),\n    epochs=100,                # Max epochs\n    batch_size=32,\n    callbacks=[early_stopping]  # Add EarlyStopping callback\n)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"evaluate_model(model)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Final result: CNN - 0.86 F1 score, 0.86 accuracy","metadata":{}},{"cell_type":"markdown","source":"## CRNN","metadata":{}},{"cell_type":"code","source":"model = Sequential([\n    # Convolutional Layers\n    Conv2D(40, (1, 14), activation='relu', input_shape=(SAMPLE_LENGTH_HZ, 14, 1)),\n    Conv2D(40, (1, 1), activation='relu'),\n    AveragePooling2D(pool_size=(5, 1)),  # Adjusted pooling to match (153, 1, 40) as in the architecture\n    Dropout(0.5),\n    \n    # TimeDistributed Flatten for RNN compatibility\n    TimeDistributed(Flatten()),  # Flatten while retaining sequence dimensions\n    \n    # LSTM Layer\n    LSTM(40, return_sequences=False),  # Extract features from the temporal dimension\n    \n    # Fully Connected Layers\n    Dense(15, activation='relu'),\n    Dense(3, activation='softmax')  # 3 classes for classification\n])\n\n# Compile the model\nmodel.compile(\n    optimizer='adam',\n    loss='categorical_crossentropy',\n    metrics=[\n        'accuracy',             # Include default accuracy metric\n        Precision(name='precision'),\n        Recall(name='recall'),\n        AUC(name='auc')         # Add AUC metric\n    ]\n)\n# Define EarlyStopping\nearly_stopping = EarlyStopping(\n    monitor='val_loss',        # Monitor validation loss\n    patience=10,               # Stop after 20 epochs with no improvement\n    restore_best_weights=True  # Restore the best weights\n)\n\n\n","metadata":{"trusted":true,"scrolled":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model.summary()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Train the model\nhistory = model.fit(\n    X_train, y_train,\n    validation_data=(X_test, y_test),\n    epochs=100,                # Max epochs\n    batch_size=32,\n    callbacks=[early_stopping]  # Add EarlyStopping callback\n)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"evaluate_model(model)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Final result: CRNN - 0.89 F1 score, 0.89 accuracy","metadata":{}},{"cell_type":"markdown","source":"## Enhanced CRNN","metadata":{}},{"cell_type":"code","source":"model = Sequential([\n    # Convolutional Layers\n    Conv2D(128, (3, 3), activation='relu', input_shape=(SAMPLE_LENGTH_HZ, 14, 1)),\n    BatchNormalization(),\n    MaxPooling2D(pool_size=(2, 2)),\n    Conv2D(256, (3, 3), activation='relu'),\n    BatchNormalization(),\n    MaxPooling2D(pool_size=(2, 2)),\n    Dropout(0.3),\n    \n    # Global Pooling for dimensionality reduction\n    TimeDistributed(Flatten()),\n    \n    # LSTM Layers\n    Bidirectional(LSTM(64, return_sequences=True)),\n    Dropout(0.3),\n    LSTM(40, return_sequences=False),\n    Dropout(0.3),\n    \n    # Fully Connected Layers\n    Dense(128, activation='relu'),\n    Dropout(0.5),\n    Dense(64, activation='relu'),\n    Dropout(0.5),\n    Dense(3, activation='softmax')\n])\n\n\n# Compile the model\nmodel.compile(\n    optimizer='adam',\n    loss='categorical_crossentropy',\n    metrics=[\n        'accuracy',             # Include default accuracy metric\n        Precision(name='precision'),\n        Recall(name='recall'),\n        AUC(name='auc')         # Add AUC metric\n    ]\n)\n\n\n","metadata":{"trusted":true,"scrolled":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model.summary()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# model.summary()\n# Define EarlyStopping\n# early_stopping = EarlyStopping(\n#     monitor='val_accuracy',       \n#     patience=10,               # Stop after 20 epochs with no improvement\n#     restore_best_weights=True  # Restore the best weights\n# )\n\n# Train the model\nhistory = model.fit(\n    X_train, y_train,\n    validation_data=(X_test, y_test),\n    epochs=100,                # Max epochs\n    batch_size=32  # Add EarlyStopping callback\n)","metadata":{"trusted":true,"scrolled":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"evaluate_model(model)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.layers import (Input, Conv2D, BatchNormalization, MaxPooling2D, Dropout,\n                                     TimeDistributed, Flatten, Bidirectional, LSTM,\n                                     Dense, GlobalAveragePooling1D, Reshape)\nfrom tensorflow.keras.metrics import Precision, Recall, AUC\nfrom tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n\n\n\n# Model inside strategy scope\nwith strategy.scope():\n    input_layer = Input(shape=(SAMPLE_LENGTH_HZ, 14, 1))\n\n    # Convolutional Layers\n    x = Conv2D(128, (3, 3), activation='relu')(input_layer)\n    x = BatchNormalization()(x)\n    x = MaxPooling2D(pool_size=(2, 2))(x)\n\n    x = Conv2D(256, (3, 3), activation='relu')(x)\n    x = BatchNormalization()(x)\n    x = MaxPooling2D(pool_size=(2, 2))(x)\n    x = Dropout(0.3)(x)\n\n    # Flatten spatial dims to feed into LSTM\n    x = TimeDistributed(Flatten())(x)\n\n    # LSTM Layers\n    x = Bidirectional(LSTM(64, return_sequences=True))(x)\n    x = Dropout(0.3)(x)\n\n    # Instead of Attention (not TPU-compatible), use GlobalAveragePooling\n    x = GlobalAveragePooling1D()(x)\n    \n    x = Reshape((1, -1))(x)  # optional if Dense expects 2D\n\n    x = LSTM(40, return_sequences=False)(x)\n    x = Dropout(0.3)(x)\n\n    # Fully Connected Layers\n    x = Dense(128, activation='relu')(x)\n    x = Dropout(0.5)(x)\n    x = Dense(64, activation='relu')(x)\n    x = Dropout(0.5)(x)\n    output = Dense(3, activation='softmax')(x)\n\n    # Build model\n    model = Model(inputs=input_layer, outputs=output)\n\n    model.compile(\n        optimizer='adam',\n        loss='categorical_crossentropy',\n        metrics=[\n            'accuracy',\n            Precision(name='precision'),\n            Recall(name='recall'),\n            AUC(name='auc')\n        ]\n    )\n\nmodel.summary()\n\n# Callbacks\nearly_stopping = EarlyStopping(monitor='val_accuracy', patience=20, restore_best_weights=True)\nlr_scheduler = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, min_lr=1e-6, verbose=1)\n\n# Fit the model\nhistory = model.fit(\n    X_train, y_train,\n    validation_data=(X_test, y_test),\n    epochs=100,\n    batch_size=32 * strategy.num_replicas_in_sync,  # optimize for TPU\n    callbacks=[early_stopping, lr_scheduler]\n)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from tensorflow.keras.models import Model\nfrom tensorflow.keras.layers import (Input, SeparableConv2D, BatchNormalization, MaxPooling2D, Dropout, \n                                     TimeDistributed, Flatten, Bidirectional, LSTM, Dense, Attention, \n                                     Reshape)\nfrom tensorflow.keras.losses import CategoricalCrossentropy\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\nfrom tensorflow.keras.metrics import Precision, Recall, AUC\n\n# Input layer\ninput_layer = Input(shape=(SAMPLE_LENGTH_HZ, 14, 1))\n\n# Convolutional Block\nx = SeparableConv2D(64, (3, 3), activation='relu')(input_layer)\nx = BatchNormalization()(x)\nx = MaxPooling2D(pool_size=(2, 2))(x)\n\nx = SeparableConv2D(128, (3, 3), activation='relu')(x)\nx = BatchNormalization()(x)\nx = MaxPooling2D(pool_size=(2, 2))(x)\nx = Dropout(0.3)(x)\n\n# Flatten spatial dims to feed into LSTM\nx = TimeDistributed(Flatten())(x)\n\n# BiLSTM Layer\nx = Bidirectional(LSTM(64, return_sequences=True))(x)\n\n# Attention block\nattention_out = Attention()([x, x])  # Query = Value = x\nx = Dropout(0.3)(attention_out)\n\n# Optional second LSTM\nx = LSTM(40, return_sequences=False)(x)\nx = Dropout(0.3)(x)\n\n# Dense Layers\nx = Dense(128, activation='relu')(x)\nx = Dropout(0.5)(x)\nx = Dense(64, activation='relu')(x)\nx = Dropout(0.5)(x)\noutput = Dense(3, activation='softmax')(x)\n\n# Model\nmodel = Model(inputs=input_layer, outputs=output)\n\n# Compile the model\nmodel.compile(\n    optimizer=Adam(),\n    loss=CategoricalCrossentropy(label_smoothing=0.1),\n    metrics=['accuracy', Precision(name='precision'), Recall(name='recall'), AUC(name='auc')]\n)\n\nmodel.summary()\n\n# Callbacks\nearly_stopping = EarlyStopping(monitor='val_accuracy', patience=10, restore_best_weights=True)\nlr_scheduler = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, min_lr=1e-6, verbose=1)\n\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"history = model.fit(\n    X_train, y_train,\n    validation_data=(X_test, y_test),\n    epochs=100,\n    batch_size=32,\n    callbacks=[early_stopping, lr_scheduler],\n    # class_weight=class_weights  # Uncomment if needed\n)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"evaluate_model(model)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import LSTM, Dense, Dropout\nfrom tensorflow.keras.metrics import Precision, Recall, AUC\nfrom tensorflow.keras.callbacks import EarlyStopping\n\n# Reshape X_train and X_test if needed\n# From shape: (samples, SAMPLE_LENGTH_HZ, 14, 1) → (samples, SAMPLE_LENGTH_HZ, 14)\n# X_train_rnn = X_train.reshape((-1, SAMPLE_LENGTH_HZ, 14))\n# X_test_rnn = X_test.reshape((-1, SAMPLE_LENGTH_HZ, 14))\n\nmodel = Sequential([\n    LSTM(64, return_sequences=True, input_shape=(SAMPLE_LENGTH_HZ, 14)),\n    Dropout(0.5),\n    LSTM(32),\n    Dropout(0.5),\n    Dense(80, activation='relu'),\n    Dense(3, activation='softmax')  # 3 output classes\n])\n\nmodel.compile(\n    optimizer='adam',\n    loss='categorical_crossentropy',\n    metrics=[\n        'accuracy',\n        Precision(name='precision'),\n        Recall(name='recall'),\n        AUC(name='auc')\n    ]\n)\n\nearly_stopping = EarlyStopping(\n    monitor='val_loss',\n    patience=10,\n    restore_best_weights=True\n)\n\n\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model.summary()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"history = model.fit(\n    X_train, y_train,\n    validation_data=(X_test, y_test),\n    epochs=100,\n    batch_size=32,\n    callbacks=[early_stopping]\n)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"evaluate_model(model)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import SimpleRNN, Dense, Dropout\nfrom tensorflow.keras.metrics import Precision, Recall, AUC\nfrom tensorflow.keras.callbacks import EarlyStopping\n\n# Reshape input: from (samples, SAMPLE_LENGTH_HZ, 14, 1) to (samples, SAMPLE_LENGTH_HZ, 14)\n# X_train_rnn = X_train.reshape((-1, SAMPLE_LENGTH_HZ, 14))\n# X_test_rnn = X_test.reshape((-1, SAMPLE_LENGTH_HZ, 14))\n\n# Build the RNN model\nmodel = Sequential([\n    SimpleRNN(64, return_sequences=True, input_shape=(SAMPLE_LENGTH_HZ, 14)),\n    Dropout(0.5),\n    SimpleRNN(32),\n    Dropout(0.5),\n    Dense(80, activation='relu'),\n    Dropout(0.5),\n    Dense(3, activation='softmax')  # 3 classes for classification\n])\n\n# Compile the model\nmodel.compile(\n    optimizer='adam',\n    loss='categorical_crossentropy',\n    metrics=[\n        'accuracy',\n        Precision(name='precision'),\n        Recall(name='recall'),\n        AUC(name='auc')\n    ]\n)\n\n# Early stopping\nearly_stopping = EarlyStopping(\n    monitor='val_loss',\n    patience=10,\n    restore_best_weights=True\n)\n\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model.summary()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Train the model\nhistory = model.fit(\n    X_train, y_train,\n    validation_data=(X_test, y_test),\n    epochs=100,\n    batch_size=32,\n    callbacks=[early_stopping]\n)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"evaluate_model(model)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def print_confusion_matrix(y_true, y_pred, report=True):\n    labels = sorted(list(set(y_true)))  # Ensure y_true contains class labels\n    cmx_data = confusion_matrix(y_true, y_pred, labels=labels)\n\n    df_cmx = pd.DataFrame(cmx_data, index=labels, columns=labels)\n\n    fig, ax = plt.subplots(figsize=(14, 12))\n    sns.heatmap(df_cmx, annot=True, fmt='g', square=False)\n    ax.set_ylim(len(set(y_true)), 0)\n    plt.xlabel(\"Predicted\")\n    plt.ylabel(\"Actual\")\n    plt.title(\"Confusion Matrix\")\n    plt.show()\n\n    if report:\n        print('Classification Report')\n        print(classification_report(y_true, y_pred))\n\n# Predict on the test set\nY_pred = model.predict(X_test)\ny_pred = np.argmax(Y_pred, axis=1)\n\n# Convert y_test from one-hot encoding to class labels\ny_test_labels = np.argmax(y_test, axis=1)\n\n# Call the function\nprint_confusion_matrix(y_test_labels, y_pred)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Final result: enhanced CRNN - 0.93 F1 score, 0.93 accuracy","metadata":{}},{"cell_type":"markdown","source":"## Transformer","metadata":{}},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\n\nclass Transformer(nn.Module):\n    def __init__(self, input_dim=14, output_dim=3, seq_len=512, d_model=32, nhead=4, num_encoder_layers=2):\n        super(Transformer, self).__init__()\n        self.input_dim = input_dim\n        self.d_model = d_model\n        self.seq_len = seq_len\n        \n        # Linear layer to project the input to the desired embedding dimension\n        self.embedding = nn.Linear(input_dim, d_model)\n        \n        # Positional encoding\n        self.positional_encoding = nn.Parameter(torch.zeros(seq_len, d_model))\n        \n        # Transformer encoder\n        self.transformer = nn.Transformer(\n            d_model=d_model,\n            nhead=nhead,\n            num_encoder_layers=num_encoder_layers,\n            dim_feedforward=256,\n            dropout=0.1,\n            batch_first=True\n        )\n        \n        # Classification head\n        self.classifier = nn.Sequential(\n            nn.Linear(d_model, 64),\n            nn.ReLU(),\n            nn.Linear(64, output_dim),\n            nn.Softmax(dim=-1)\n        )\n\n    def forward(self, x):\n        # x shape: (batch_size, seq_len, input_dim, 1) -> (batch_size, seq_len, input_dim)\n        x = x.squeeze(-1)\n        \n        # Project input to d_model dimension\n        x = self.embedding(x)  # (batch_size, seq_len, d_model)\n        \n        # Add positional encoding\n        x = x + self.positional_encoding\n        \n        # Pass through Transformer encoder\n        x = self.transformer(x, x)  # (batch_size, seq_len, d_model)\n        \n        # Take the mean across the sequence length (global pooling)\n        x = x.mean(dim=1)  # (batch_size, d_model)\n        \n        # Pass through classification head\n        out = self.classifier(x)  # (batch_size, output_dim)\n        return out\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"batch_size = 32\nseq_len = 512\ninput_dim = 14\nmodel = Transformer(input_dim=input_dim)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def count_parameters(model):\n    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n\nprint(f\"Number of trainable parameters: {count_parameters(model)}\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch.optim as optim\nfrom torch.utils.data import DataLoader, TensorDataset\n\n# Check if GPU is available and set the device\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}\")\n\n# Move the model to the GPU\nmodel = model.to(device)\n\n# Define the loss function and optimizer\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.Adam(model.parameters(), lr=0.001)\n\n# Convert data to PyTorch tensors and move to GPU\nX_train_tensor = torch.tensor(X_train, dtype=torch.float32).to(device)\ny_train_tensor = torch.tensor(y_train.argmax(axis=1), dtype=torch.long).to(device)\n\nX_test_tensor = torch.tensor(X_test, dtype=torch.float32).to(device)\ny_test_tensor = torch.tensor(y_test.argmax(axis=1), dtype=torch.long).to(device)\n\n# Create DataLoaders\ntrain_dataset = TensorDataset(X_train_tensor, y_train_tensor)\ntrain_loader = DataLoader(train_dataset, batch_size=128, shuffle=True)\n\ntest_dataset = TensorDataset(X_test_tensor, y_test_tensor)\ntest_loader = DataLoader(test_dataset, batch_size=128, shuffle=False)\n\n\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"epochs = 30\nfor epoch in range(epochs):\n    print(epoch)\n    model.train()  # Set the model to training mode\n    running_loss = 0.0\n    correct = 0\n    total = 0\n    \n    for X_batch, y_batch in train_loader:\n        \n        # Move data to GPU\n        X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n        \n        optimizer.zero_grad()  # Clear gradients\n        \n        # Forward pass\n        outputs = model(X_batch)\n        \n        # Calculate loss\n        loss = criterion(outputs, y_batch)\n        \n        # Backward pass and optimization\n        loss.backward()\n        optimizer.step()\n        \n        # Calculate running loss and accuracy\n        running_loss += loss.item()\n        _, predicted = outputs.max(1)\n        total += y_batch.size(0)\n        correct += (predicted == y_batch).sum().item()\n        \n    epoch_loss = running_loss / len(train_loader)\n    epoch_accuracy = 100.0 * correct / total\n    print(f\"Epoch {epoch+1}/{epochs}, Loss: {epoch_loss:.4f}, Accuracy: {epoch_accuracy:.2f}%\")\n\n# Evaluation on test set\nmodel.eval()  # Set the model to evaluation mode\ntest_correct = 0\ntest_total = 0\n\nwith torch.no_grad():\n    for X_batch, y_batch in test_loader:\n        # Move data to GPU\n        X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n        \n        outputs = model(X_batch)\n        _, predicted = outputs.max(1)\n        test_total += y_batch.size(0)\n        test_correct += (predicted == y_batch).sum().item()\n\ntest_accuracy = 100.0 * test_correct / test_total\nprint(f\"Test Accuracy: {test_accuracy:.2f}%\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.metrics import f1_score\n\nmodel.eval()  # Set the model to evaluation mode\ntest_correct = 0\ntest_total = 0\n\nall_predictions = []\nall_labels = []\n\nwith torch.no_grad():\n    for X_batch, y_batch in test_loader:\n        # Move data to GPU\n        X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n        \n        outputs = model(X_batch)\n        _, predicted = outputs.max(1)\n        \n        # Save predictions and true labels\n        all_predictions.extend(predicted.cpu().numpy())\n        all_labels.extend(y_batch.cpu().numpy())\n        \n        test_total += y_batch.size(0)\n        test_correct += (predicted == y_batch).sum().item()\n\ntest_accuracy = 100.0 * test_correct / test_total\nf1 = f1_score(all_labels, all_predictions, average='weighted')  \nprint(f\"Test Accuracy: {test_accuracy:.2f}%\")\nprint(f\"F1 Score: {f1:.2f}\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Final result: Transformer - 0.86 F1 score, 0.86 accuracy","metadata":{}},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**07/04/2025**","metadata":{}},{"cell_type":"code","source":"from sklearn.decomposition import PCA\n\n# Flatten 4D to 2D: (samples, time_steps * channels)\nX_flattened = X.reshape(X.shape[0], -1)\ny_labels = np.argmax(y, axis=1)\n\n# Reduce to 100 components\npca = PCA(n_components=100)\nX_pca = pca.fit_transform(X_flattened)\n\nX_train_svm, X_test_svm, y_train_svm, y_test_svm = train_test_split(\n    X_pca, y_labels, test_size=0.2, random_state=42\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-07T05:04:03.419209Z","iopub.execute_input":"2025-04-07T05:04:03.419560Z","iopub.status.idle":"2025-04-07T05:04:18.156297Z","shell.execute_reply.started":"2025-04-07T05:04:03.419526Z","shell.execute_reply":"2025-04-07T05:04:18.155609Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.svm import SVC\nfrom sklearn.metrics import classification_report, confusion_matrix","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-07T05:04:53.641731Z","iopub.execute_input":"2025-04-07T05:04:53.642058Z","iopub.status.idle":"2025-04-07T05:04:53.646247Z","shell.execute_reply.started":"2025-04-07T05:04:53.642029Z","shell.execute_reply":"2025-04-07T05:04:53.645303Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"svm_model = SVC(kernel='rbf', C=1)\nsvm_model.fit(X_train_svm, y_train_svm)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-07T05:04:54.057653Z","iopub.execute_input":"2025-04-07T05:04:54.057917Z","iopub.status.idle":"2025-04-07T05:05:14.155285Z","shell.execute_reply.started":"2025-04-07T05:04:54.057891Z","shell.execute_reply":"2025-04-07T05:05:14.154440Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score, classification_report, confusion_matrix, roc_auc_score\n\ndef evaluate_svm_model(model, X_test, y_test):\n    y_pred = model.predict(X_test)\n\n    precision = precision_score(y_test, y_pred, average='macro')\n    recall = recall_score(y_test, y_pred, average='macro')\n    f1 = f1_score(y_test, y_pred, average='macro')\n    accuracy = accuracy_score(y_test, y_pred)\n\n    # Print all metrics\n    print(f\"Test Accuracy: {accuracy:.4f}\")\n    print(f\"Test Precision (macro): {precision:.4f}\")\n    print(f\"Test Recall (macro): {recall:.4f}\")\n    print(f\"Test F1 Score (macro): {f1:.4f}\")\n    print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n\n    # Confusion Matrix\n    cm = confusion_matrix(y_test, y_pred)\n    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n    plt.title(\"Confusion Matrix\")\n    plt.xlabel(\"Predicted\")\n    plt.ylabel(\"Actual\")\n    plt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-07T05:06:00.868408Z","iopub.execute_input":"2025-04-07T05:06:00.869244Z","iopub.status.idle":"2025-04-07T05:06:00.875547Z","shell.execute_reply.started":"2025-04-07T05:06:00.869210Z","shell.execute_reply":"2025-04-07T05:06:00.874610Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"evaluate_svm_model(svm_model, X_test_svm, y_test_svm)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-07T05:06:05.058438Z","iopub.execute_input":"2025-04-07T05:06:05.059112Z","iopub.status.idle":"2025-04-07T05:06:10.177810Z","shell.execute_reply.started":"2025-04-07T05:06:05.059080Z","shell.execute_reply":"2025-04-07T05:06:10.176936Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"PCA 150 COMPONENTS","metadata":{}},{"cell_type":"code","source":"X_flattened = X.reshape(X.shape[0], -1)\ny_labels = np.argmax(y, axis=1)\n\n# Step 2: Standardize before PCA (optional but helps)\nscaler = StandardScaler()\nX_scaled = scaler.fit_transform(X_flattened)\n\n# Step 3: PCA\npca = PCA(n_components=150)  # Try 100, 150, 200 and compare\nX_pca = pca.fit_transform(X_scaled)\n\n# Step 4: Train-test split\nX_train_svm, X_test_svm, y_train_svm, y_test_svm = train_test_split(\n    X_pca, y_labels, test_size=0.2, random_state=42, stratify=y_labels\n)\n\n# Step 5: SVM with optimized hyperparameters\nsvm_model = SVC(kernel='rbf', C=10, gamma='scale', probability=True)\nsvm_model.fit(X_train_svm, y_train_svm)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-07T05:08:59.556769Z","iopub.execute_input":"2025-04-07T05:08:59.557406Z","iopub.status.idle":"2025-04-07T05:12:11.835897Z","shell.execute_reply.started":"2025-04-07T05:08:59.557373Z","shell.execute_reply":"2025-04-07T05:12:11.834940Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"evaluate_svm_model(svm_model, X_test_svm, y_test_svm)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-07T05:12:54.662054Z","iopub.execute_input":"2025-04-07T05:12:54.662882Z","iopub.status.idle":"2025-04-07T05:13:04.576843Z","shell.execute_reply.started":"2025-04-07T05:12:54.662848Z","shell.execute_reply":"2025-04-07T05:13:04.576047Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**ANN**","metadata":{}},{"cell_type":"code","source":"from tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Dropout, Flatten\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.metrics import Precision, Recall, AUC\nfrom tensorflow.keras.callbacks import EarlyStopping\n\n# Flatten data for ANN\nX_flattened = X.reshape(X.shape[0], -1)  # Shape: (samples, 728 * 14)\n\n# Split into train/test\nX_train_flat, X_test_flat, y_train_ann, y_test_ann = train_test_split(\n    X_flattened, y, test_size=0.2, random_state=42\n)\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-07T05:14:24.406521Z","iopub.execute_input":"2025-04-07T05:14:24.407274Z","iopub.status.idle":"2025-04-07T05:14:25.297238Z","shell.execute_reply.started":"2025-04-07T05:14:24.407245Z","shell.execute_reply":"2025-04-07T05:14:25.296245Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Build ANN model\nann_model = Sequential([\n    Dense(256, activation='relu', input_shape=(X_flattened.shape[1],)),\n    Dropout(0.3),\n    Dense(128, activation='relu'),\n    Dropout(0.3),\n    Dense(64, activation='relu'),\n    Dropout(0.2),\n    Dense(3, activation='softmax')  # 3 classes\n])\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-07T05:14:28.381864Z","iopub.execute_input":"2025-04-07T05:14:28.382528Z","iopub.status.idle":"2025-04-07T05:14:29.419195Z","shell.execute_reply.started":"2025-04-07T05:14:28.382495Z","shell.execute_reply":"2025-04-07T05:14:29.418287Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Compile model\nann_model.compile(\n    optimizer=Adam(learning_rate=0.001),\n    loss='categorical_crossentropy',\n    metrics=['accuracy', Precision(), Recall(), AUC()]\n)\n\n# Train the model\nearly_stop = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-07T05:14:29.420874Z","iopub.execute_input":"2025-04-07T05:14:29.421626Z","iopub.status.idle":"2025-04-07T05:14:29.445622Z","shell.execute_reply.started":"2025-04-07T05:14:29.421586Z","shell.execute_reply":"2025-04-07T05:14:29.445028Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\nhistory = ann_model.fit(\n    X_train_flat, y_train_ann,\n    validation_split=0.2,\n    epochs=50,\n    batch_size=64,\n    callbacks=[early_stop],\n    verbose=1\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-07T05:14:37.142628Z","iopub.execute_input":"2025-04-07T05:14:37.143181Z","iopub.status.idle":"2025-04-07T05:15:01.219450Z","shell.execute_reply.started":"2025-04-07T05:14:37.143147Z","shell.execute_reply":"2025-04-07T05:15:01.218769Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Evaluate the model\ndef evaluate_ann_model(model,X_test,y_test):\n    results = model.evaluate(X_test, y_test)\n    test_loss, test_accuracy, test_precision, test_recall, test_auc = results\n    test_f1 = f1_score(test_precision, test_recall)\n    # Print results\n    print(f\"Test Loss: {test_loss:.4f}\")\n    print(f\"Test Accuracy: {test_accuracy:.4f}\")\n    print(f\"Test Precision: {test_precision:.4f}\")\n    print(f\"Test Recall: {test_recall:.4f}\")\n    print(f\"Test AUC: {test_auc:.4f}\")\n    print(f\"Test F1: {test_f1:.4f}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-07T05:19:42.841888Z","iopub.execute_input":"2025-04-07T05:19:42.842650Z","iopub.status.idle":"2025-04-07T05:19:42.847527Z","shell.execute_reply.started":"2025-04-07T05:19:42.842611Z","shell.execute_reply":"2025-04-07T05:19:42.846631Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"evaluate_ann_model(ann_model,X_test_flat,y_test_ann)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-07T05:19:43.341705Z","iopub.execute_input":"2025-04-07T05:19:43.342008Z","iopub.status.idle":"2025-04-07T05:19:45.021615Z","shell.execute_reply.started":"2025-04-07T05:19:43.341982Z","shell.execute_reply":"2025-04-07T05:19:45.020760Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**CNN + LSTM**","metadata":{}},{"cell_type":"code","source":"from tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import TimeDistributed, Conv2D, MaxPooling2D, Flatten\nfrom tensorflow.keras.layers import LSTM, Dropout, Dense, BatchNormalization\nfrom tensorflow.keras.metrics import Precision, Recall, AUC\nfrom tensorflow.keras.optimizers import Adam\n\nmodel = Sequential()\n\n# Apply Conv2D across time-distributed EEG frames\nmodel.add(TimeDistributed(Conv2D(32, (3, 3), activation='relu'), input_shape=(128, 4, 14, 1)))\nmodel.add(TimeDistributed(MaxPooling2D((2, 2))))\nmodel.add(TimeDistributed(BatchNormalization()))\nmodel.add(TimeDistributed(Flatten()))\n\n# LSTM to learn sequence\nmodel.add(LSTM(64, return_sequences=False))\nmodel.add(Dropout(0.5))\n\n# Fully connected output\nmodel.add(Dense(64, activation='relu'))\nmodel.add(Dense(3, activation='softmax'))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-07T05:23:30.693543Z","iopub.execute_input":"2025-04-07T05:23:30.693862Z","iopub.status.idle":"2025-04-07T05:23:30.976381Z","shell.execute_reply.started":"2025-04-07T05:23:30.693833Z","shell.execute_reply":"2025-04-07T05:23:30.975644Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Compile\nmodel.compile(\n    optimizer=Adam(learning_rate=0.001),\n    loss='categorical_crossentropy',\n    metrics=['accuracy', Precision(), Recall(), AUC()]\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-07T05:23:40.811342Z","iopub.execute_input":"2025-04-07T05:23:40.812211Z","iopub.status.idle":"2025-04-07T05:23:40.830903Z","shell.execute_reply.started":"2025-04-07T05:23:40.812174Z","shell.execute_reply":"2025-04-07T05:23:40.830373Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\nmodel.summary()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-07T05:23:51.179702Z","iopub.execute_input":"2025-04-07T05:23:51.180032Z","iopub.status.idle":"2025-04-07T05:23:51.201067Z","shell.execute_reply.started":"2025-04-07T05:23:51.180004Z","shell.execute_reply":"2025-04-07T05:23:51.200322Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"X_cnn_lstm = X.reshape(X.shape[0], 128, 4, 14, 1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-07T05:25:14.147705Z","iopub.execute_input":"2025-04-07T05:25:14.148515Z","iopub.status.idle":"2025-04-07T05:25:14.152403Z","shell.execute_reply.started":"2025-04-07T05:25:14.148479Z","shell.execute_reply":"2025-04-07T05:25:14.151511Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model.fit(X_cnn_lstm, y, validation_split=0.2, epochs=30, batch_size=64)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-07T05:25:16.245663Z","iopub.execute_input":"2025-04-07T05:25:16.245964Z","iopub.status.idle":"2025-04-07T05:44:16.927460Z","shell.execute_reply.started":"2025-04-07T05:25:16.245938Z","shell.execute_reply":"2025-04-07T05:44:16.926636Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\n# Make sure you split after reshaping\nX_train, X_test, y_train, y_test = train_test_split(X_cnn_lstm, y, test_size=0.2, random_state=42)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-07T05:44:41.264695Z","iopub.execute_input":"2025-04-07T05:44:41.265538Z","iopub.status.idle":"2025-04-07T05:44:41.700372Z","shell.execute_reply.started":"2025-04-07T05:44:41.265493Z","shell.execute_reply":"2025-04-07T05:44:41.699669Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.metrics import f1_score as sk_f1_score, classification_report, confusion_matrix\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport numpy as np\n\ndef evaluate_cnn_lstm_model(model, X_test, y_test):\n    # Get predictions\n    y_pred_prob = model.predict(X_test)\n    y_pred = np.argmax(y_pred_prob, axis=1)\n    y_true = np.argmax(y_test, axis=1)\n\n    # Evaluate metrics\n    test_loss, test_accuracy, test_precision, test_recall, test_auc = model.evaluate(X_test, y_test, verbose=0)\n    test_f1 = 2 * ((test_precision * test_recall) / (test_precision + test_recall + 1e-8))\n\n    # Print results\n    print(f\"Test Loss: {test_loss:.4f}\")\n    print(f\"Test Accuracy: {test_accuracy:.4f}\")\n    print(f\"Test Precision: {test_precision:.4f}\")\n    print(f\"Test Recall: {test_recall:.4f}\")\n    print(f\"Test AUC: {test_auc:.4f}\")\n    print(f\"Test F1 Score: {test_f1:.4f}\")\n\n    # Classification Report\n    print(\"\\nClassification Report:\\n\", classification_report(y_true, y_pred))\n\n    # Confusion Matrix\n    cm = confusion_matrix(y_true, y_pred)\n    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n    plt.title(\"Confusion Matrix\")\n    plt.xlabel(\"Predicted\")\n    plt.ylabel(\"Actual\")\n    plt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-07T05:44:56.265540Z","iopub.execute_input":"2025-04-07T05:44:56.265862Z","iopub.status.idle":"2025-04-07T05:44:56.273091Z","shell.execute_reply.started":"2025-04-07T05:44:56.265835Z","shell.execute_reply":"2025-04-07T05:44:56.272198Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"evaluate_cnn_lstm_model(model, X_test, y_test)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-07T05:45:11.584943Z","iopub.execute_input":"2025-04-07T05:45:11.585293Z","iopub.status.idle":"2025-04-07T05:45:26.679152Z","shell.execute_reply.started":"2025-04-07T05:45:11.585255Z","shell.execute_reply":"2025-04-07T05:45:26.678329Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"CNN + lstm + svm","metadata":{}},{"cell_type":"code","source":"import numpy as np\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, BatchNormalization, Flatten\nfrom tensorflow.keras.layers import TimeDistributed, LSTM\nfrom tensorflow.keras.optimizers import Adam\n\n# Reshape your data (Assumes original X shape is (samples, 128, 4, 14))\nX_cnn_lstm = X.reshape(X.shape[0], 128, 4, 14, 1)\ny_labels = np.argmax(y, axis=1)\n\n# Build the CNN-LSTM Feature Extractor\ninput_layer = Input(shape=(128, 4, 14, 1))\n\nx = TimeDistributed(Conv2D(64, (3, 3), activation='relu', padding='same'))(input_layer)\nx = TimeDistributed(BatchNormalization())(x)\nx = TimeDistributed(MaxPooling2D((2, 2)))(x)\n\nx = TimeDistributed(Conv2D(128, (3, 3), activation='relu', padding='same'))(x)\nx = TimeDistributed(BatchNormalization())(x)\nx = TimeDistributed(MaxPooling2D((2, 2)))(x)\n\nx = TimeDistributed(Flatten())(x)\nx = LSTM(128, return_sequences=False)(x)\n\n# Define feature extractor model\nfeature_extractor = Model(inputs=input_layer, outputs=x)\nfeature_extractor.compile(optimizer=Adam(), loss='mse')\nfeature_extractor.summary()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-07T05:51:34.349011Z","iopub.execute_input":"2025-04-07T05:51:34.349841Z","iopub.status.idle":"2025-04-07T05:51:34.436214Z","shell.execute_reply.started":"2025-04-07T05:51:34.349806Z","shell.execute_reply":"2025-04-07T05:51:34.435516Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Extract CNN-LSTM features\nfeatures = feature_extractor.predict(X_cnn_lstm, verbose=1)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-07T05:51:44.651806Z","iopub.execute_input":"2025-04-07T05:51:44.652133Z","iopub.status.idle":"2025-04-07T05:52:23.954613Z","shell.execute_reply.started":"2025-04-07T05:51:44.652105Z","shell.execute_reply":"2025-04-07T05:52:23.953875Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\nX_train_svm, X_test_svm, y_train_svm, y_test_svm = train_test_split(\n    features, y_labels, test_size=0.2, random_state=42\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-07T05:53:57.761895Z","iopub.execute_input":"2025-04-07T05:53:57.762246Z","iopub.status.idle":"2025-04-07T05:53:57.772396Z","shell.execute_reply.started":"2025-04-07T05:53:57.762214Z","shell.execute_reply":"2025-04-07T05:53:57.771525Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.svm import SVC\n\nsvm_model = SVC(kernel='rbf', C=10, gamma='scale', probability=True)  # You can tune C, gamma\nsvm_model.fit(X_train_svm, y_train_svm)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-07T05:54:00.206877Z","iopub.execute_input":"2025-04-07T05:54:00.207572Z","iopub.status.idle":"2025-04-07T05:56:29.152239Z","shell.execute_reply.started":"2025-04-07T05:54:00.207528Z","shell.execute_reply":"2025-04-07T05:56:29.151387Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, f1_score\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\ndef evaluate_svm_model(model, X_test, y_test):\n    y_pred = model.predict(X_test)\n\n    print(f\"Accuracy: {accuracy_score(y_test, y_pred):.4f}\")\n    print(f\"F1 Score (macro): {f1_score(y_test, y_pred, average='macro'):.4f}\")\n    print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n\n    cm = confusion_matrix(y_test, y_pred)\n    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n    plt.title(\"Confusion Matrix\")\n    plt.xlabel(\"Predicted\")\n    plt.ylabel(\"Actual\")\n    plt.show()\n\n# Call the evaluation\nevaluate_svm_model(svm_model, X_test_svm, y_test_svm)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-07T05:57:21.935554Z","iopub.execute_input":"2025-04-07T05:57:21.936141Z","iopub.status.idle":"2025-04-07T05:57:28.359453Z","shell.execute_reply.started":"2025-04-07T05:57:21.936107Z","shell.execute_reply":"2025-04-07T05:57:28.358650Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**RANDOM FOREST**","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, f1_score\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\ndef evaluate_random_model(model, X_test, y_test):\n    y_pred = model.predict(X_test)\n\n    print(f\"Accuracy: {accuracy_score(y_test, y_pred):.4f}\")\n    print(f\"F1 Score (macro): {f1_score(y_test, y_pred, average='macro'):.4f}\")\n    print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n\n    cm = confusion_matrix(y_test, y_pred)\n    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n    plt.title(\"Confusion Matrix\")\n    plt.xlabel(\"Predicted\")\n    plt.ylabel(\"Actual\")\n    plt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-07T06:01:00.001591Z","iopub.execute_input":"2025-04-07T06:01:00.002427Z","iopub.status.idle":"2025-04-07T06:01:00.007948Z","shell.execute_reply.started":"2025-04-07T06:01:00.002394Z","shell.execute_reply":"2025-04-07T06:01:00.007073Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\nfrom sklearn.decomposition import PCA\n\nX_flattened = X.reshape(X.shape[0], -1)\ny_labels = np.argmax(y, axis=1)\n\n# Optional: Reduce dimensions\npca = PCA(n_components=100)\nX_pca = pca.fit_transform(X_flattened)\n\nX_train_rf, X_test_rf, y_train_rf, y_test_rf = train_test_split(X_pca, y_labels, test_size=0.2)\n\nrf_model = RandomForestClassifier(n_estimators=200)\nrf_model.fit(X_train_rf, y_train_rf)\ny_pred = rf_model.predict(X_test_rf)\n\nprint(classification_report(y_test_rf, y_pred))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-07T05:58:46.055758Z","iopub.execute_input":"2025-04-07T05:58:46.056604Z","iopub.status.idle":"2025-04-07T05:59:48.502140Z","shell.execute_reply.started":"2025-04-07T05:58:46.056567Z","shell.execute_reply":"2025-04-07T05:59:48.501295Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"evaluate_random_model(rf_model, X_test_rf, y_test_rf)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-07T06:01:42.793766Z","iopub.execute_input":"2025-04-07T06:01:42.794118Z","iopub.status.idle":"2025-04-07T06:01:43.258874Z","shell.execute_reply.started":"2025-04-07T06:01:42.794087Z","shell.execute_reply":"2025-04-07T06:01:43.258016Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**TRANSFORMER MODEL**","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport tensorflow as tf\nfrom tensorflow.keras import layers, models\nfrom tensorflow.keras.layers import Dense, Dropout, LayerNormalization, MultiHeadAttention\nfrom tensorflow.keras.models import Model\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report, confusion_matrix, accuracy_score\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# ✅ Assuming you have EEG data ready as (samples, 512, 14)\n# X shape: (samples, 512, 14)\n# y shape: one-hot encoded with 3 classes\n\n# Split data\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# -------------------------------\n# Transformer Encoder Block\n# -------------------------------\ndef transformer_encoder(inputs, head_size=64, num_heads=4, ff_dim=128, dropout=0.1):\n    # Multi-head self-attention\n    x = MultiHeadAttention(num_heads=num_heads, key_dim=head_size)(inputs, inputs)\n    x = Dropout(dropout)(x)\n    x = LayerNormalization(epsilon=1e-6)(x + inputs)\n\n    # Feed-forward network with residual\n    ff = layers.Dense(ff_dim, activation=\"relu\")(x)\n    ff = layers.Dense(x.shape[-1])(ff)  # Ensures matching dimensions\n    ff = Dropout(dropout)(ff)\n    x = LayerNormalization(epsilon=1e-6)(x + ff)\n    return x\n\n# -------------------------------\n# Build the Transformer Model\n# -------------------------------\ninput_layer = layers.Input(shape=(512, 14))\n\n# Positional Encoding (simple learnable projection here)\nx = layers.Dense(64)(input_layer)\n\n# Stack multiple transformer blocks\nfor _ in range(2):  # try 2 or 3 layers\n    x = transformer_encoder(x)\n\n# Global pooling and dense layers\nx = layers.GlobalAveragePooling1D()(x)\nx = Dropout(0.3)(x)\nx = Dense(64, activation='relu')(x)\nx = Dropout(0.3)(x)\noutput_layer = Dense(3, activation='softmax')(x)\n\nmodel = Model(inputs=input_layer, outputs=output_layer)\n\n# Compile\nmodel.compile(optimizer='adam',\n              loss='categorical_crossentropy',\n              metrics=['accuracy',\n                       tf.keras.metrics.Precision(name='precision'),\n                       tf.keras.metrics.Recall(name='recall'),\n                       tf.keras.metrics.AUC(name='auc')])\n\nmodel.summary()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-07T06:21:42.964002Z","iopub.execute_input":"2025-04-07T06:21:42.964340Z","iopub.status.idle":"2025-04-07T06:21:43.560722Z","shell.execute_reply.started":"2025-04-07T06:21:42.964309Z","shell.execute_reply":"2025-04-07T06:21:43.559840Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"history = model.fit(X_train, y_train, validation_split=0.2, epochs=30, batch_size=64)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-07T06:21:54.205394Z","iopub.execute_input":"2025-04-07T06:21:54.206210Z","iopub.status.idle":"2025-04-07T06:36:08.987136Z","shell.execute_reply.started":"2025-04-07T06:21:54.206175Z","shell.execute_reply":"2025-04-07T06:36:08.986528Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# -------------------------------\n# Evaluation Function\n# -------------------------------\ndef evaluate_model(model, X_test, y_test):\n    results = model.evaluate(X_test, y_test)\n    test_loss, test_accuracy, test_precision, test_recall, test_auc = results\n    test_f1 = 2 * (test_precision * test_recall) / (test_precision + test_recall + 1e-7)\n\n    print(f\"\\nTest Loss: {test_loss:.4f}\")\n    print(f\"Test Accuracy: {test_accuracy:.4f}\")\n    print(f\"Test Precision: {test_precision:.4f}\")\n    print(f\"Test Recall: {test_recall:.4f}\")\n    print(f\"Test AUC: {test_auc:.4f}\")\n    print(f\"Test F1 Score: {test_f1:.4f}\")\n\n    # Classification report\n    y_pred = model.predict(X_test)\n    y_pred_classes = np.argmax(y_pred, axis=1)\n    y_true = np.argmax(y_test, axis=1)\n\n    print(\"\\nClassification Report:\\n\", classification_report(y_true, y_pred_classes))\n\n    cm = confusion_matrix(y_true, y_pred_classes)\n    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n    plt.title(\"Confusion Matrix\")\n    plt.xlabel(\"Predicted\")\n    plt.ylabel(\"True\")\n    plt.show()\n\n# -------------------------------\n# Evaluate\n# -------------------------------\nevaluate_model(model, X_test, y_test)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-07T06:36:49.268167Z","iopub.execute_input":"2025-04-07T06:36:49.268537Z","iopub.status.idle":"2025-04-07T06:36:59.161969Z","shell.execute_reply.started":"2025-04-07T06:36:49.268497Z","shell.execute_reply":"2025-04-07T06:36:59.160199Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}